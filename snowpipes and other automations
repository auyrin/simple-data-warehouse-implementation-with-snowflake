// CREATE SCHEMA FOR SNOWPIPES
CREATE OR REPLACE SCHEMA MANAGE_DB.PIPES;

// CREATE YOUR SALES PIPE
CREATE OR REPLACE PIPE MANAGE_DB.PIPES.SALES_PIPE
AUTO_INGEST = TRUE
AS 
COPY INTO DWH.staging.sales_raw
FROM @DWH.EXTERNAL_STAGES.AWS_STAGE
;

DESC PIPE MANAGE_DB.PIPES.SALES_PIPE;

// CHECK IG IF OUR SNOWPIPE IS RUNNING
SELECT SYSTEM$PIPE_STATUS( 'MANAGE_DB.PIPES.SALES_PIPE' );

// PAUSE THE SNOWPIPE(WHENEVER) because it might consume too much resources
alter pipe manage_db.pipes.sales_pipe
set PIPE_EXECUTION_PAUSED = TRUE;


// before i upload new files in the aws s3 buckets that'll be copied automatically
// by my snowpipe. lets automate the staging area processes.


// AUTOMATE THE STAGING TO CORE PIPELINE via SCHEDULED TASKS

// steps: check pipe, truncate table if pending tasks, run snowpipe, do the neccessary transformations. insert into the core table

// an if statement that'll checkk and execute if some conditions are met
IF 
-- check if there is a pending file in the snow pipe
 (SELECT JSON_EXTRACT_PATH_TEXT(SYSTEM$PIPE_STATUS( 'MANAGE_DB.PIPES.SALES_PIPE' ), 'pendingFileCount') > 0) THEN 
-- if there is a file then truncate the sales table in the staging area
TRUNCATE DWH.STAGING.SALES_RAW;
END IF;


-- RUN THE SNOWPIPE
ALTER PIPE MANAGE_DB.PIPES.SALES_PIPE
SET PIPE_EXECUTION_PAUSED = FALSE;

--necessary transformations are in the load and transform file. lets do everything in a task.
