// CREATE SCHEMA FOR SNOWPIPES
CREATE OR REPLACE SCHEMA MANAGE_DB.PIPES;

// CREATE YOUR SALES PIPE
CREATE OR REPLACE PIPE MANAGE_DB.PIPES.SALES_PIPE
AUTO_INGEST = TRUE
AS 
COPY INTO DWH.staging.sales_raw
FROM @DWH.EXTERNAL_STAGES.AWS_STAGE
;

DESC PIPE MANAGE_DB.PIPES.SALES_PIPE;

// CHECK IG IF OUR SNOWPIPE IS RUNNING
SELECT SYSTEM$PIPE_STATUS( 'MANAGE_DB.PIPES.SALES_PIPE' );

// PAUSE THE SNOWPIPE(WHENEVER) because it might consume too much resources
alter pipe manage_db.pipes.sales_pipe
set PIPE_EXECUTION_PAUSED = TRUE;


// before i upload new files in the aws s3 buckets that'll be copied automatically
// by my snowpipe. lets automate the staging area processes.


// AUTOMATE THE STAGING TO CORE PIPELINE via SCHEDULED TASKS

// steps: check pipe, truncate table if pending tasks, run snowpipe, do the neccessary transformations. insert into the core table

// lets create a procedure for checking our snowpipe

-- javascript procedure
CREATE OR REPLACE PROCEDURE DWH.PUBLIC.check_pipe_prod()
RETURNS STRING
LANGUAGE JAVASCRIPT
AS
$$
    var sql_command;
    var pending;

    // Step 1: Get the pendingFileCount from SYSTEM$PIPE_STATUS
    sql_command = `SELECT TO_NUMBER(JSON_EXTRACT_PATH_TEXT(SYSTEM$PIPE_STATUS('MANAGE_DB.PIPES.SALES_PIPE'), 'pendingFileCount')) AS pendingFileCount`;
    
    // Step 2: Execute the query and fetch the result
    var result = snowflake.execute({ sqlText: sql_command });
    result.next(); // Move to the first row
    pending = result.getColumnValue(1); // Get the pending file count

    // Step 3: Check if pendingFileCount is greater than 0
    if (pending > 0) {
        // Step 4: Truncate the table dynamically
        sql_command = `TRUNCATE TABLE DWH.STAGING.SALES_RAW`;
        snowflake.execute({ sqlText: sql_command });

        // Step 5: Un-pause the Snowpipe
        sql_command = `ALTER PIPE MANAGE_DB.PIPES.SALES_PIPE SET PIPE_EXECUTION_PAUSED = FALSE`;
        snowflake.execute({ sqlText: sql_command });

        return 'Staging table truncated...sales_pipe is running';
    } else {
        return 'No pending files in our sales_pipe';
    }
$$;


CALL CHECK_PIPE_PROD();

-- our goal is to put everything in a single task due to the nature of what i want to do.



-- first lets make procedure that'll do the transformation
CREATE OR REPLACE PROCEDURE DWH.PUBLIC.TRANSFORM_LOAD_PROD()
RETURNS STRING
LANGUAGE SQL
AS
BEGIN
    insert into dwh.core.sales_fact
    SELECT 
	"transaction_id",
	"transaction_date",
	EXTRACT(year from "transaction_date")*10000 + EXTRACT(month from "transaction_date")*100+EXTRACT(day from "transaction_date")as 	"transaction_date_fk",
	s."product_id" ,
	p."product_pk" as "product_fk",
	py."payment_pk" as "payment_fk",
    "customer_id",
    "credit_card",
   	"cost",
    "quantity",
   	"price",
    "cost" * "quantity" as "total_cost",
    "price" * "quantity" as "total_price",
    "total_price" - "total_cost" as "profit"
    FROM dwh.staging.sales_raw s
    LEFT JOIN 
    dwh.core.payment_dim py
    ON py."payment" = COALESCE(s."payment",'cash') AND py."loyalty_card"=s."loyalty_card"
    LEFT JOIN dwh.core.product_dim p on p."product_id"=s."product_id"
    order by "transaction_id";
END;



-- i'll create another procedure that'll check all the conditions we need to check that'll make the staging area function correctly.

CREATE OR REPLACE PROCEDURE dwh.public.STAGING_AREA_PROD()
RETURNS STRING
LANGUAGE JAVASCRIPT
AS
$$
    try {
        // Step 1: Call the check_pipe_prod procedure and get the value
        var pipe_value_command = `CALL dwh.public.check_pipe_prod()`;
        var pipe_value_result = snowflake.execute({ sqlText: pipe_value_command });
        var pipe_value = '';

        if (pipe_value_result.next()) {
            pipe_value = pipe_value_result.getColumnValue(1);
        } else {
            return "Error: Unable to retrieve pipe status.";
        }

        // Step 2: Get the last transaction ID from the sales_fact table
        var last_load_command = `SELECT MAX("transaction_id") AS last_load FROM dwh.core.sales_fact`;
        var last_load_result = snowflake.execute({ sqlText: last_load_command });
        var last_load = null;

        if (last_load_result.next()) {
            last_load = last_load_result.getColumnValue(1);
        } else {
            return "Error: Unable to retrieve last transaction ID.";
        }

        // Step 3: Conditional logic based on pipe_value
        if (pipe_value === "Staging table truncated...sales_pipe is running") {
        
            // check to make sure it's not duplicated
            var sql_command = 'select min("transaction_id") from dwh.staging.sales_raw';
            var result = snowflake.execute({sqlText: sql_command});
            if (result.next()) {
                load = result.getColumnValue(1);
            } else {
                return "Error: Unable to retrieve last transaction ID.";
            }
            
            // update the table if the first value meets the condition
            if (load > last_load) {
                // Transformation and loading logic here
                sql_command = 'call transform_load_prod';
                snowflake.execute({sqlText: sql_command});
            } else {
                return 'some data already loaded to the core';
            }
            

            return 'Files loaded';
        } else if (pipe_value === "No pending files in our sales_pipe") {
            return "No files loaded";
        } else {
            return "Unexpected pipe status value: " + pipe_value;
        }
    } catch (err) {
        return "Error: " + err.message;
    }
$$;

-- create our tasks to automate this process

// task would run every sunday at 7am utc

-- parent task
CREATE OR REPLACE TASK DWH.PUBLIC.CHECK_PIPE_TASK
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 MINUTE'
    -- SCHEDULE = 'USING CRON 0 7 * * SUN UTC'
    AS
    CALL DWH.PUBLIC.CHECK_PIPE_PROD();

alter task dwh.public.check_pipe_task SUSPEND;

show tasks;

-- i need a delay in between, just to make sure the pipe has finished running

-- Intermediate Delay Task
CREATE OR REPLACE TASK DWH.PUBLIC.DELAY_TASK
  WAREHOUSE = COMPUTE_WH
  AFTER DWH.PUBLIC.CHECK_PIPE_TASK
  AS
  SELECT SYSTEM$WAIT(300); -- This waits 5 minutes (300 seconds)


-- child task
CREATE OR REPLACE TASK DWH.PUBLIC.staging_area_TASK
    WAREHOUSE = COMPUTE_WH
    AFTER DWH.PUBLIC.DELAY_TASK
    AS
    CALL DWH.PUBLIC.STAGING_AREA_PROD();



