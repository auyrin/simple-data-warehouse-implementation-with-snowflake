// CREATE SCHEMA FOR SNOWPIPES
CREATE OR REPLACE SCHEMA MANAGE_DB.PIPES;

// CREATE YOUR SALES PIPE
CREATE OR REPLACE PIPE MANAGE_DB.PIPES.SALES_PIPE
AUTO_INGEST = TRUE
AS 
COPY INTO DWH.staging.sales_raw
FROM @DWH.EXTERNAL_STAGES.AWS_STAGE
;

DESC PIPE MANAGE_DB.PIPES.SALES_PIPE;

// CHECK IG IF OUR SNOWPIPE IS RUNNING
SELECT SYSTEM$PIPE_STATUS( 'MANAGE_DB.PIPES.SALES_PIPE' );

// PAUSE THE SNOWPIPE(WHENEVER) because it might consume too much resources
alter pipe manage_db.pipes.sales_pipe
set PIPE_EXECUTION_PAUSED = TRUE;


// before i upload new files in the aws s3 buckets that'll be copied automatically
// by my snowpipe. lets automate the staging area processes.


// AUTOMATE THE STAGING TO CORE PIPELINE via SCHEDULED TASKS

// steps: check pipe, truncate table if pending tasks, run snowpipe, do the neccessary transformations. insert into the core table

// lets create a procedure for checking our snowpipe-- javascript procedure
CREATE OR REPLACE PROCEDURE DWH.PUBLIC.check_pipe_prod()
RETURNS STRING
LANGUAGE JAVASCRIPT
AS
$$
    var sql_command;
    var pending;

    // Step 1: Get the pendingFileCount from SYSTEM$PIPE_STATUS
    sql_command = `SELECT TO_NUMBER(JSON_EXTRACT_PATH_TEXT(SYSTEM$PIPE_STATUS('MANAGE_DB.PIPES.SALES_PIPE'), 'pendingFileCount')) AS pendingFileCount`;
    
    // Step 2: Execute the query and fetch the result
    var result = snowflake.execute({ sqlText: sql_command });
    result.next(); // Move to the first row
    pending = result.getColumnValue(1); // Get the pending file count

    // Step 3: Check if pendingFileCount is greater than 0
    if (pending > 0) {
        // Step 4: Truncate the table dynamically
        sql_command = `TRUNCATE TABLE DWH.STAGING.SALES_RAW`;
        snowflake.execute({ sqlText: sql_command });

        // Step 5: Un-pause the Snowpipe
        sql_command = `ALTER PIPE MANAGE_DB.PIPES.SALES_PIPE SET PIPE_EXECUTION_PAUSED = FALSE`;
        snowflake.execute({ sqlText: sql_command });

        return 'Staging table truncated...sales_pipe is running';
    } else {
        // Step 6: Suspend the parent task
        sql_command = `ALTER TASK DWH.PUBLIC.CHECK_PIPE_TASK SUSPEND`;
        snowflake.execute({ sqlText: sql_command });

        return 'No pending files in our sales_pipe';
    }
$$;


CALL CHECK_PIPE_PROD();


--necessary transformations are in the load and transform file. lets put everything in a task.

// task would run every sunday at 7am utc
CREATE OR REPLACE TASK DWH.PUBLIC.CHECK_PIPE_TASK
    WAREHOUSE = COMPUTE_WH
    SCHEDULE  = '1 MINUTE'
    -- SCHEDULE = 'USING CRON 0 7 * * SUN UTC'
    AS
    CALL DWH.PUBLIC.CHECK_PIPE_PROD();

alter task dwh.public.check_pipe_task SUSPEND;

show tasks;

// CHILD TASK SHOULD DO THE TRANSFORMATIONS ONLY IF THE SALES TABLE HAS BEEN UPDATED

-- STEPS .... select the result of the parent task and only run the child task if the parent task has been executed.

-- investigate your pause logic

CREATE OR REPLACE TASK DWH.PUBLIC.TRANSFORMATION_TASK
    WAREHOUSE = COMPUTE_WH
    AFTER DWH.PUBLIC.CHECK_PIPE_TASK
    AS
    select * from dwh.core.product_dim;

select max("transaction_id") from dwh.core.sales_fact;


alter task dwh.public.transformation_task resume;



select * from table(information_schema.task_history());
