// CREATE SCHEMA FOR SNOWPIPES
CREATE OR REPLACE SCHEMA MANAGE_DB.PIPES;

// CREATE YOUR SALES PIPE
CREATE OR REPLACE PIPE MANAGE_DB.PIPES.SALES_PIPE
AUTO_INGEST = TRUE
AS 
COPY INTO DWH.staging.sales_raw
FROM @DWH.EXTERNAL_STAGES.AWS_STAGE
;

DESC PIPE MANAGE_DB.PIPES.SALES_PIPE;

// CHECK IG IF OUR SNOWPIPE IS RUNNING
SELECT SYSTEM$PIPE_STATUS( 'MANAGE_DB.PIPES.SALES_PIPE' );

// PAUSE THE SNOWPIPE(WHENEVER) because it might consume too much resources
alter pipe manage_db.pipes.sales_pipe
set PIPE_EXECUTION_PAUSED = TRUE;


// before i upload new files in the aws s3 buckets that'll be copied automatically
// by my snowpipe. lets automate the staging area processes.


// AUTOMATE THE STAGING TO CORE PIPELINE via SCHEDULED TASKS

// steps: check pipe, truncate table if pending tasks, run snowpipe, do the neccessary transformations. insert into the core table

// lets create a procedure for checking our snowpipe

-- javascript procedure
CREATE OR REPLACE PROCEDURE DWH.PUBLIC.check_pipe_prod()
RETURNS STRING
LANGUAGE JAVASCRIPT
AS
$$
    var sql_command;
    var pending;

    // Step 1: Get the pendingFileCount from SYSTEM$PIPE_STATUS
    sql_command = `SELECT TO_NUMBER(JSON_EXTRACT_PATH_TEXT(SYSTEM$PIPE_STATUS('MANAGE_DB.PIPES.SALES_PIPE'), 'pendingFileCount')) AS pendingFileCount`;
    
    // Step 2: Execute the query and fetch the result
    var result = snowflake.execute({ sqlText: sql_command });
    result.next(); // Move to the first row
    pending = result.getColumnValue(1); // Get the pending file count

    // Step 3: Check if pendingFileCount is greater than 0
    if (pending > 0) {
        // Step 4: Truncate the table dynamically
        sql_command = `TRUNCATE TABLE DWH.STAGING.SALES_RAW`;
        snowflake.execute({ sqlText: sql_command });

        // Step 5: Un-pause the Snowpipe
        sql_command = `ALTER PIPE MANAGE_DB.PIPES.SALES_PIPE SET PIPE_EXECUTION_PAUSED = FALSE`;
        snowflake.execute({ sqlText: sql_command });

        return 'Staging table truncated...sales_pipe is running';
    } else {
        return 'No pending files in our sales_pipe';
    }
$$;


CALL CHECK_PIPE_PROD();

-- our goal is to put everything in a single task due to the nature of what i want to do.

-- i'll create another procedure for the transformations i need to do, but with the conditions that make the staging area function correctly

CREATE OR REPLACE PROCEDURE dwh.public.TRANSFORM_LOAD_PROD()
RETURNS STRING
LANGUAGE JAVASCRIPT
AS
$$
    try {
        // Step 1: Call the check_pipe_prod procedure and get the value
        var pipe_value_command = `CALL dwh.public.check_pipe_prod()`;
        var pipe_value_result = snowflake.execute({ sqlText: pipe_value_command });
        var pipe_value = '';

        if (pipe_value_result.next()) {
            pipe_value = pipe_value_result.getColumnValue(1);
        } else {
            return "Error: Unable to retrieve pipe status.";
        }

        // Step 2: Get the last transaction ID from the sales_fact table
        var last_load_command = `SELECT MAX("transaction_id") AS last_load FROM dwh.core.sales_fact`;
        var last_load_result = snowflake.execute({ sqlText: last_load_command });
        var last_load = null;

        if (last_load_result.next()) {
            last_load = last_load_result.getColumnValue(1);
        } else {
            return "Error: Unable to retrieve last transaction ID.";
        }

        // Step 3: Conditional logic based on pipe_value
        if (pipe_value === "Staging table truncated...sales_pipe is running") {
            // Transformation and loading logic here
            // Assuming we would perform transformation and load to the core area
            // Add your transformation/load code here

            return 'Files loaded';
        } else if (pipe_value === "No pending files in our sales_pipe") {
            return "No files loaded";
        } else {
            return "Unexpected pipe status value: " + pipe_value;
        }
    } catch (err) {
        return "Error: " + err.message;
    }
$$;


call transform_load_prod();



select * from table(information_schema.task_history());
